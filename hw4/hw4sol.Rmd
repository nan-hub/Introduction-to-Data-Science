---
title: "30-Day Mortality Rate of Cardiac Arrest Patients Admitted to CCU"
author: Nan Liu
output:
  html_document:
    toc: true
    toc_depth: 4
  # ioslides_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

In this research, we use MIMIC-III data set. MIMIC-III (Medical Information Mart for Intensive Care III) is a database comprising deidentified health-related data associated with over forty thousand patients who stayed in critical care units of the Beth Israel Deaconess Medical Center between 2001 and 2012.The database provides information such as demographics, vital sign measurements made at the bedside, laboratory test results, procedures, medications, caregiver notes, imaging reports, and mortality (both in and out of hospital).

This report focus on the analysis of mortality rate of cardiac arrest 30 days after discharge from hospital.

# Data preparation
## Connect to PostgresSQL database
Load database libraries and the tidyverse frontend:
```{r}
library(DBI)
library(RPostgreSQL)
library(tidyverse)
library(lubridate)
```

Credentials for using PostgreSQL database. We are going to use username `postgres` with password `postgres` to access the `mimic` database in the schemee `mimiciii`. 
```{r}
# Load configuration settings
dbdriver <- 'PostgreSQL'
user  <- 'postgres'
password <- 'postgres'
dbname <- 'mimic'
schema <- 'mimiciii'
# Connect to the database using the configuration settings
con <- dbConnect(RPostgreSQL::PostgreSQL(), 
                 dbname = dbname, 
                 user = user, 
                 password = password)
# Set the default schema
dbExecute(con, paste("SET search_path TO ", schema, sep =" "))
con

#lapply(dbListConnections(PostgreSQL()), dbDisconnect)
```


## Query and subsetting
Create a cohort of patients who were directly admitted into CCU and were diagnosed with cardiac arrest.

First we create a (query) table of patients who were directly admitted into CCU.
```{r}
tbl(con, "transfers") %>%
  select(subject_id, hadm_id, prev_careunit, curr_careunit) %>%
  filter(is.na(prev_careunit) & curr_careunit == "CCU") %>%
  select(subject_id, hadm_id) %>%
  distinct() %>%
  print() -> ccu_admissions
```

Now we want to restrict to cardiac arrest patients. To find all possible ICD-9 codes related to cardiac arrest, we search for string `cardiac arrest` in the `long_title` of table `d_icd_diagnoses`:
```{r}
tbl(con, "d_icd_diagnoses") %>%
  filter(str_detect(tolower(long_title), "cardiac arrest")) %>% #ignore upper lower letter
  print() -> ca_codes
```

`diagnoses_icd` table stores the diagnosis of each admission. We use `semi_join()` to keep the rows in `diagnoses_icd` that match the ICD-9 codes related to cardiac arrest:
```{r}
tbl(con, "diagnoses_icd") %>%
  semi_join(ca_codes, by = "icd9_code") %>%
  print() -> ca_admissions
```

CA(Cardiac Arrest) may not be listed as the principal diagnosis; as explained in [the documentation for the `patients` table](https://mimic.physionet.org/mimictables/diagnoses_icd/), the `seq_num` field is a priority ranking for the diagnoses generated at the end of stay. In order to focus on patients for whom CA was central to their hospitalization, we will include records with CA in any of the first five diagnosis positions, according to the `seq_num` field. To avoid duplicate admissions, we use `group_by()` and `top_n()` to limit the query to the first CA diagnosis for each admission.
```{r}
ca_admissions %>%
  filter(seq_num <= 5) %>%
  group_by(subject_id, hadm_id) %>%
  filter(min_rank(seq_num) <= 1) %>%
  ungroup() %>%
  select(subject_id, hadm_id, icd9_code, seq_num) %>%
  print() -> ca_admissions
```


Now we `inner_join` the table of admissions to CCU and the table of admissions that include CA diagnosis.
```{r}
ccu_admissions %>%
  inner_join(ca_admissions, by = c("subject_id", "hadm_id")) %>%
  print() -> study_admissions
```

## Transform and augment query tables

Now we create a logical variable indicating the CA is the principal diagonosis or not (according to `seq_num`).
```{r}
study_admissions %>%
  mutate(principal_dx = seq_num == 1) %>%
  select(-seq_num) %>%
  print() -> study_admissions
```

We want to add information about the severity of patients’ ailments. The `drgcodes` table contains, for `DRG` codes from the All Payers Registry (APR), severity and mortality indicators. We pull the drug severity information and right-join it to our query table.
```{r}
tbl(con, "drgcodes") %>%
  filter(str_detect(drg_type, "APR")) %>%
  select(subject_id, hadm_id, drg_severity) %>%
  right_join(study_admissions, by = c("subject_id", "hadm_id")) %>%
  mutate(drg_severity = ifelse(is.na(drg_severity), 1, drg_severity)) %>%
  group_by(subject_id, hadm_id) %>%
  summarise (drg_severity = mean(drg_severity, na.rm = TRUE)) %>%
  print() -> study_admissions
```


Pull the admission time `admittime`, discharge time `dischtime`, date of birth `dob`, and date of death `dod`. We are interested in the  mortaility rate 30 days after discharge. So we only keep patients who didn't die in hospital.
```{r}
study_admissions %>%
  left_join(
    select(tbl(con, "admissions"),
           subject_id, hadm_id, admittime, dischtime, hospital_expire_flag
    ), by = c("subject_id","hadm_id")
  ) %>%
  filter(hospital_expire_flag == 0) %>% # patients who did not die in hospital
  select(-hospital_expire_flag) %>%
  left_join(
    select(tbl(con, "patients"), subject_id, dob, dod),
    by = "subject_id"
  ) %>%
  print(width = Inf) -> study_admissions
```

To add `age` (at admission) variable into the table. [The documentation for the patients table](https://mimic.physionet.org/mimictables/patients/) explains that patients of 90 years and older had their ages artificially inflated, so we remove these patients from the analysis. Also create new variable `death` to indicate whether the patient dies or not in 30 days.
```{r}
study_admissions %>%
  mutate(dyear = date_part("year", dod) - date_part("year", dischtime)) %>%
  mutate(dmonth = date_part("month", dod) - date_part("month", dischtime)) %>%
  mutate(dday = date_part("day", dod) - date_part("day", dischtime)) %>%
  mutate(death = ifelse(
  (dyear == 0) & (dmonth <= 1) & (dday <= 0) |
    (
     (dyear == 0) & (dmonth == 0) & (dday >= 0) 
    ),
  1,
  NA
)) %>%

  mutate(age = date_part("year", admittime) - date_part("year", dob)) %>%
  filter(age < 90) %>%
  mutate(age = age - ifelse(
    date_part("month", admittime) < date_part("month", dob) |
      (
        date_part("month", admittime) == date_part("month", dob) &
          date_part("day", admittime) < date_part("day", dob)
      ),
    1,
    0
  )) %>%
  select(-admittime, -dischtime, -dob, -dod, -dyear, -dmonth, -dday) %>%
  select(subject_id, hadm_id, age, death, everything()) %>%
  print() -> study_admissions
```

To add `admission_location` variable into the table:

```{r}
tbl(con, "admissions") %>%
  select(subject_id, hadm_id, admission_location) %>%
  right_join(study_admissions, by = c("subject_id", "hadm_id")) %>%
  print() -> study_admissions
```

Many mortality indicators are missing, due to neither the hospital database nor the social security database having a record of these patients’ deaths. We could convert these to `FALSE` values, but it may be helpful to retain in the analytic table this information on whether deaths were recorded at all, e.g. for validation or sensitivity testing.

Finally, let's merge some demographic information (ethnicity, gender) into our study `study_admissions`.
```{r}
tbl(con, "admissions") %>%
  select(subject_id, ethnicity) %>%
  distinct() %>%
  print() -> study_subjects
```

```{r}
tbl(con, "patients") %>%
  select(subject_id, gender) %>%
  distinct() %>%
  full_join(study_subjects, by = "subject_id") %>%
  print() -> study_subjects
```

```{r}
study_subjects %>%
  semi_join(study_admissions, by = "subject_id") %>%
  print() -> study_subjects
```

Let's resolves ome diversity and inconsistency in the `ethnicity` field:
```{r}
unknown_ethnicity <- c(
  "OTHER",
  "UNABLE TO OBTAIN",
  "UNKNOWN/NOT SPECIFIED",
  "MULTI RACE ETHNICITY",
  "PATIENT DECLINED TO ANSWER",
  "UNKNOWN"
)

study_subjects %>%
  collect() %>%
  mutate(ethnic_group = case_when(
    str_detect(ethnicity, "^ASIAN") ~ "ASIAN",
    str_detect(ethnicity, "^BLACK") ~ "BLACK",
    str_detect(ethnicity, "^HISPANIC") ~ "HISPANIC",
    str_detect(ethnicity, "^WHITE") ~ "WHITE",
    ethnicity %in% unknown_ethnicity ~ NA_character_,
    TRUE ~ NA_character_
  )) %>%
  select(subject_id, gender, ethnic_group) %>%
  print() -> study_subjects
```

Some patients are coded as belonging to more than one ethnic group. To resolve these inconsistencies, we define a helper function to pick the modal value from a vector of values in R, which can be used by the `summarize()` function to choose one ethnic group for each patient.
```{r}
most <- function(x) {
  if (all(is.na(x))) return(NA_character_)
  y <- table(x, useNA = "no")
  if (length(which(y == max(y))) > 1) return(NA_character_)
  return(names(y)[which.max(y)])
}

study_subjects %>%
  group_by(subject_id) %>%
  summarize(ethnic_group = most(ethnic_group)) %>%
  ungroup() %>%
  mutate(ethnic_group = ifelse(is.na(ethnic_group), "UNKNOWN", ethnic_group)) %>% 
  print() -> subject_ethnic_groups
```

```{r}
study_subjects %>%
  select(subject_id, gender) %>%
  left_join(subject_ethnic_groups, by = "subject_id") %>%
  distinct() %>%
  print() -> study_subjects
```


Now we add the demographic information `gender` and `ethnicity` into our `study_admissions` table:
```{r}
study_admissions %>%
  left_join(study_subjects,  by = "subject_id", copy = TRUE) %>%
  distinct() %>%
  print -> study_admissions
```


## Study cohort

CONSORT Flow Diagrams can be used to plot the flow of data selection of a patient cohort. 

```{r plot}
library(shape)
library(diagram)

# set margins and multiplot
par(mfrow = c(1, 1))
par(mar = c(0, 0, 0, 0))

# initialise a plot device
openplotmat()

# position of boxes
# 1st column indicates x axis position between 0 and 1
# 2nd column indicates y axis position between 0 and 1
# automatically assigns vertical position
num_of_boxes <- 5
auto_coords = coordinates(num_of_boxes)
vert_pos = rev(auto_coords[,1])
box_pos <- matrix(nrow = num_of_boxes, ncol = 2, data = 0)
box_pos[1,] = c(0.20, vert_pos[1]) # 1st box
box_pos[2,] = c(0.70, vert_pos[2]) # 2nd box
box_pos[3,] = c(0.70, vert_pos[3]) # 3rd box
box_pos[4,] = c(0.70, vert_pos[4]) # 4th box
box_pos[5,] = c(0.20, vert_pos[5]) # 5th box

# content of boxes
box_content <- matrix(nrow = num_of_boxes, ncol = 1, data = 0)
box_content[1] = "All patients in CCU \n n = 1000" # 1st box
box_content[2] = "Exclude patients whose first 5 diagnosis \n does not include Cardiac Arrest \n n = 697" # 2nd box
box_content[3] = "Exclude patients who dies in hospital \n n = 110" # 3rd box
box_content[4] = "Exclude patients whose age>90 \n n = 8" # etc...
box_content[5] = "Study cohort \n n = 185"

# adjust the size of boxes to fit content
box_x <- c(0.20, 0.25, 0.25, 0.25, 0.20)
box_y <- c(0.07, 0.07, 0.07, 0.07, 0.07)

# Draw the arrows
straightarrow(from = c(box_pos[1,1],box_pos[2,2]), to = box_pos[2,], lwd = 1)  
straightarrow(from = c(box_pos[1,1],box_pos[3,2]), to = box_pos[3,], lwd = 1)  
straightarrow(from = c(box_pos[1,1],box_pos[4,2]), to = box_pos[4,], lwd = 1)  
straightarrow(from = box_pos[1,], to = box_pos[5,], lwd = 1)

# Draw the boxes
for (i in 1:num_of_boxes) {
  textrect(mid = box_pos[i,], radx = box_x[i], rady = box_y[i], 
           lab = box_content[i], 
           shadow.col = "grey")
  }
```

# Data Visualization
First, let's display the first 10 lines of `study_admissions`:
```{r}
head(study_admissions)
```

## Bar plot of mortality
```{r}
study_admissions %>%
   mutate(livedeath =ifelse(is.na(death) == FALSE, 1, 0)) %>%
   ggplot() + 
   geom_bar(mapping = aes(x = livedeath)) + 
   labs(x = "mortality")
```

## Bar plot of age

```{r}
study_admissions %>%
  ggplot() + 
  geom_bar(mapping = aes(x = age)) + 
  labs(x = "Age")
```


## Bar plot of gender

```{r}
study_admissions %>%
  ggplot() + 
  geom_bar(mapping = aes(x = gender)) + 
  labs(x = "Gender")
```


## Bar plot of ethnic_group

```{r}
study_admissions %>%
  ggplot() + 
  geom_bar(mapping = aes(x = ethnic_group)) + 
  labs(x = "Ethnic")
```

## Bar plot of admission location

```{r}
study_admissions %>%
  ggplot() + 
  geom_bar(mapping = aes(x = admission_location)) + 
  labs(x = "Admission location") +
  theme(axis.text.x = element_text(size  = 8,
                                   angle = 45,
                                   hjust = 1,
                                   vjust = 1))
```

## Bar plot of drug severity

```{r}
study_admissions %>%
  ggplot() + 
  geom_bar(mapping = aes(x = drg_severity)) + 
  labs(x = "Drug severity")
```


# Analytics

## Logistic Regression

We first use logistic regression method to analysis the mortality rate of Cardiac Arrest in 30 days.

Split data to train set and test set. Then build the model.
```{r}
studyad<- study_admissions %>%
   mutate(livedeath = ifelse(is.na(death) == FALSE, 1, 0))
model_df<-as.data.frame(studyad)
set.seed(123)
#split data in to 70% traing set and 30% test set
s <- sample(nrow(model_df), floor(nrow(model_df)*0.7), replace = F)
train <- model_df[s,]
test <- model_df[-s,]
mylogit <- glm(livedeath ~ age + gender + ethnic_group + admission_location  
               + drg_severity, data = train, family = binomial, maxit = 10000)
#use logistic method to find minist AIC
step <- step(mylogit, direction ='both')
summary(step)
```

Testing: Evaluate model performance on the test data.

```{r}
install.packages("pROC")
library(pROC)
install.packages("plotROC")
library(plotROC)
install.packages("DMwR")
library(DMwR)
```

```{r}
pred <- predict(step, test, type = 'response')
fitted.r <- ifelse(pred >= 0.5, 1, 0)
accuracy <- table(fitted.r, test$livedeath)
roc <- roc(test$livedeath, pred)
plot(roc)
roc
```

The area under the curve is 0.5063. So the model built from this data set is not very accurate. 3 in 56 people will die for Cardiac Arrest in 30 days after being admitted to CCU. The 30-Day Mortality Rate of Cardiac Arrest Patients Admitted to CCU is about 5.4%.

## Neural network

I try 2 different methods of neural netwok. 

First I use Keras package to specify and train models.

Aquire data:
```{r}
library(keras)
train_x <-train[,-9]
train_y<- train[ ,9]
test_x <- test[,-9]
test_y<- test[ ,9]
```

Prepare data:

Make scale entries to [0, 1]. Transform `trainx` and `testx` in to matrix. 

```{r}
trainx <- train_x %>%
  mutate( age = age / max(age),
          gender = ifelse (gender == "F", 1, 0),
          drg_severity = drg_severity / max(drg_severity),
          ethnic_group = ifelse(ethnic_group == "WHITE", 1, ethnic_group),
          ethnic_group = ifelse(ethnic_group == "BLACK", 2, ethnic_group),
          ethnic_group = ifelse(ethnic_group == "UNKNOWN", 3, ethnic_group),
          ethnic_group = ifelse(ethnic_group == "ASIAN", 4, ethnic_group),
          ethnic_group = ifelse(ethnic_group == "HISPANIC", 5, ethnic_group),
          ethnic_group = as.numeric(ethnic_group) / 5,
          admission_location = ifelse(admission_location == 
                          "TRANSFER FROM HOSP/EXTRAM", 1, admission_location),
          admission_location = ifelse(admission_location == 
                          "CLINIC REFERRAL/PREMATURE", 2, admission_location),
          admission_location = ifelse(admission_location == 
                                "EMERGENCY ROOM ADMIT", 3, admission_location),
          admission_location = ifelse(admission_location == 
                           "PHYS REFERRAL/NORMAL DELI", 4, admission_location),
          admission_location = as.numeric(admission_location) / 4
         ) %>%
  select(-c(subject_id, hadm_id, death))
trainx <- as.matrix(trainx)

testx<-test_x %>%
  mutate( age = age / max(age),
          gender = ifelse (gender == "F", 1, 0),
          drg_severity = drg_severity / max(drg_severity),
          ethnic_group = ifelse(ethnic_group == "WHITE", 1, ethnic_group),
          ethnic_group = ifelse(ethnic_group == "BLACK", 2, ethnic_group),
          ethnic_group = ifelse(ethnic_group == "UNKNOWN", 3, ethnic_group),
          ethnic_group = ifelse(ethnic_group == "ASIAN", 4, ethnic_group),
          ethnic_group = ifelse(ethnic_group == "HISPANIC", 5, ethnic_group),
          ethnic_group = as.numeric(ethnic_group) / 5,
          admission_location = ifelse(admission_location == 
                             "TRANSFER FROM HOSP/EXTRAM",1, admission_location),
          admission_location = ifelse(admission_location == 
                             "CLINIC REFERRAL/PREMATURE",2, admission_location),
          admission_location = ifelse(admission_location == 
                             "EMERGENCY ROOM ADMIT",3, admission_location),
          admission_location = ifelse(admission_location == 
                             "PHYS REFERRAL/NORMAL DELI",4, admission_location),
          admission_location = as.numeric(admission_location) / 4
         ) %>%
  select(-c(subject_id, hadm_id, death))
testx <- as.matrix(testx)
```

Encode $y$ as binary class matrix:

```{r}
train_y <- to_categorical(train_y, 2)
test_y <- to_categorical(test_y, 2)
```

Define a **sequential model** (a linear stack of layers) with 2 fully-connected hidden layers (256 and 128 neurons):

```{r}
model <- keras_model_sequential() 
model %>% 
  layer_dense(units = 256, activation = 'relu', input_shape = c(5)) %>% 
  layer_dropout(rate = 0.4) %>% 
  layer_dense(units = 128, activation = 'relu') %>%
  layer_dropout(rate = 0.3) %>%
  layer_dense(units = 2, activation = 'softmax')
summary(model)
```

Compile the model with appropriate loss function, optimizer, and metrics:
```{r}
model %>% compile(
  loss = 'categorical_crossentropy',
  optimizer = optimizer_rmsprop(),
  metrics = c('accuracy')
)
```

Training and validation:
```{r}
system.time({
history <- model %>% fit(
  trainx, train_y, 
  epochs = 30, batch_size = 128, 
  validation_split = 0.2
)
})
plot(history)
```

Testing:
Evaluate model performance on the test data:
```{r}
model %>% evaluate(testx, test_y)
```

Generate predictions on new data:
```{r}
predict <- model %>% predict_classes(testx) 
mean(predict)
```

The accuracy is about 94.6%.
The 30-Day Mortality Rate of Cardiac Arrest Patients Admitted to CCU is about 5.4%.


Then I try another method with `DMwR` package and nnet function:

```{r}
install.packages("DMwR")
```

```{r}
library(lattice)
library(grid)
library(DMwR)
library(nnet)
```

Define the model:
After multiple try, I found maxit = 270 can achieve high accuracy around 72.33%
```{r}
live.nn<-nnet(livedeath ~ age + gender + ethnic_group + admission_location + 
                drg_severity, data = train, size = 5, decay = 5e-4, maxit = 270)
summary(live.nn)
```


Evaluate model performance on the test data:

```{r}
install.packages("pROC")
library(pROC)
install.packages("plotROC")
library(plotROC)
install.packages("DMwR")
library(DMwR)
pred2 <- predict(live.nn, test)
fitted.r2 <- ifelse(pred2 >= 0.5, 1, 0)
accuracy2 <- table(fitted.r2, test$livedeath)
roc2 <- roc(test$livedeath, pred2)
plot(roc2)
roc2
```

3 in 56 people will die for Cardiac Arrest in 30 days after being admitted to CCU. The 30-Day Mortality Rate of Cardiac Arrest Patients Admitted to CCU is about 5.4%.


Plot the neural:
```{r}
install.packages("reshape")
```

```{r}
library(reshape)
library(nnet)
library(devtools)
library(reshape2)
source_url('https://gist.githubusercontent.com/Peque/41a9e20d6687f2f3108d/raw/85e14f3a292e126f1454864427e3a189c2fe33f3/nnet_plot_update.r')
plot.nnet(live.nn, alpha.val = 0.5, circle.col = list('lightgray', 'white'), 
          bord.col = 'black')
```

# Close the connection to a database

Close the connection:
```{r}
dbDisconnect(con)
```

# Conclusions
The results from logistic regression method and neural network method are similiar. The 30-Day Mortality Rate of Cardiac Arrest Patients Admitted to CCU is about 5.4%. However, the model built from neural network has higher accuracy. The model from keras package has accuacy around 94.6% and the model from nnet function is about 72.33%.








